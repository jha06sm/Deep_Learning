{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGI2PBib89g1",
        "outputId": "1b36876b-6e9a-482c-cb91-accb03d8e434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.12/dist-packages (1.26.7)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.4)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.7)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.6.4)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.13.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.6)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (2.5.0)\n",
            "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-text-splitters) (1.2.7)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.6.4)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.12.3)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.13.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.5.0)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (1.2.7)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (1.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.45)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.4)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (0.13.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.3.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.41.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        }
      ],
      "source": [
        "!pip install PyMuPDF\n",
        "!pip install langchain\n",
        "!pip install langchain-text-splitters\n",
        "!pip install langchain_community\n",
        "import fitz  # PyMuPDF\n",
        "from langchain_core.documents import Document\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "import torch\n",
        "import numpy as np\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.messages import HumanMessage\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import os\n",
        "import base64\n",
        "import io\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###Clip Model\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "load_dotenv()\n",
        "\n",
        "## set up the environment\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "if not openai_api_key:\n",
        "  openai_api_key = input(\"Please enter your OpenAI API Key: \")\n",
        "  if not openai_api_key:\n",
        "    raise ValueError(\"OPENAI_API_KEY not provided.\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "### initialize the Clip Model for unified embeddings\n",
        "clip_model=CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "clip_processor=CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "clip_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq_2RRXw9G53",
        "outputId": "f6b582cd-e902-43de-de07-92a8a8efe54f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your OpenAI API Key: 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\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CLIPModel(\n",
              "  (text_model): CLIPTextTransformer(\n",
              "    (embeddings): CLIPTextEmbeddings(\n",
              "      (token_embedding): Embedding(49408, 512)\n",
              "      (position_embedding): Embedding(77, 512)\n",
              "    )\n",
              "    (encoder): CLIPEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x CLIPEncoderLayer(\n",
              "          (self_attn): CLIPAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): CLIPMLP(\n",
              "            (activation_fn): QuickGELUActivation()\n",
              "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          )\n",
              "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (vision_model): CLIPVisionTransformer(\n",
              "    (embeddings): CLIPVisionEmbeddings(\n",
              "      (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
              "      (position_embedding): Embedding(50, 768)\n",
              "    )\n",
              "    (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (encoder): CLIPEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x CLIPEncoderLayer(\n",
              "          (self_attn): CLIPAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): CLIPMLP(\n",
              "            (activation_fn): QuickGELUActivation()\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (visual_projection): Linear(in_features=768, out_features=512, bias=False)\n",
              "  (text_projection): Linear(in_features=512, out_features=512, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "### Embedding functions\n",
        "def embed_image(image_data):\n",
        "    \"\"\"Embed image using CLIP\"\"\"\n",
        "    if isinstance(image_data, str):  # If path\n",
        "        image = Image.open(image_data).convert(\"RGB\")\n",
        "    else:  # If PIL Image\n",
        "        image = image_data\n",
        "\n",
        "    inputs=clip_processor(images=image,return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        features = clip_model.get_image_features(**inputs)\n",
        "        # Normalize embeddings to unit vector\n",
        "        features = features / features.norm(dim=-1, keepdim=True)\n",
        "        return features.squeeze().numpy()\n",
        "\n",
        "def embed_text(text):\n",
        "    \"\"\"Embed text using CLIP.\"\"\"\n",
        "    inputs = clip_processor(\n",
        "        text=text,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=77  # CLIP's max token length\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        features = clip_model.get_text_features(**inputs)\n",
        "        # Normalize embeddings\n",
        "        features = features / features.norm(dim=-1, keepdim=True)\n",
        "        return features.squeeze().numpy()"
      ],
      "metadata": {
        "id": "tWFYK8RW-zZp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "## Process PDF\n",
        "pdf_path=\"/content/SatyamJha_Resume.pdf\"\n",
        "doc=fitz.open(pdf_path)\n",
        "# Storage for all documents and embeddings\n",
        "all_docs = []\n",
        "all_embeddings = []\n",
        "image_data_store = {}  # Store actual image data for LLM\n",
        "\n",
        "# Text splitter\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)"
      ],
      "metadata": {
        "id": "_gKssgfQ_vjr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhvgLsLi_0Oj",
        "outputId": "51bda9b2-1361-4062-c5fc-431eaa8bc228"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document('/content/SatyamJha_Resume.pdf')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "for i,page in enumerate(doc):\n",
        "    ## process text\n",
        "    text=page.get_text()\n",
        "    if text.strip():\n",
        "        ##create temporary document for splitting\n",
        "        temp_doc = Document(page_content=text, metadata={\"page\": i, \"type\": \"text\"})\n",
        "        text_chunks = splitter.split_documents([temp_doc])\n",
        "\n",
        "        #Embed each chunk using CLIP\n",
        "        for chunk in text_chunks:\n",
        "            embedding = embed_text(chunk.page_content)\n",
        "            all_embeddings.append(embedding)\n",
        "            all_docs.append(chunk)\n",
        "\n",
        "\n",
        "\n",
        "    ## process images\n",
        "    ##Three Important Actions:\n",
        "\n",
        "    ##Convert PDF image to PIL format\n",
        "    ##Store as base64 for GPT-4V (which needs base64 images)\n",
        "    ##Create CLIP embedding for retrieval\n",
        "\n",
        "    for img_index, img in enumerate(page.get_images(full=True)):\n",
        "        try:\n",
        "            xref = img[0]\n",
        "            base_image = doc.extract_image(xref)\n",
        "            image_bytes = base_image[\"image\"]\n",
        "\n",
        "            # Convert to PIL Image\n",
        "            pil_image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
        "\n",
        "            # Create unique identifier\n",
        "            image_id = f\"page_{i}_img_{img_index}\"\n",
        "\n",
        "            # Store image as base64 for later use with GPT-4V\n",
        "            buffered = io.BytesIO()\n",
        "            pil_image.save(buffered, format=\"PNG\")\n",
        "            img_base64 = base64.b64encode(buffered.getvalue()).decode()\n",
        "            image_data_store[image_id] = img_base64\n",
        "\n",
        "            # Embed image using CLIP\n",
        "            embedding = embed_image(pil_image)\n",
        "            all_embeddings.append(embedding)\n",
        "\n",
        "            # Create document for image\n",
        "            image_doc = Document(\n",
        "                page_content=f\"[Image: {image_id}]\",\n",
        "                metadata={\"page\": i, \"type\": \"image\", \"image_id\": image_id}\n",
        "            )\n",
        "            all_docs.append(image_doc)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image {img_index} on page {i}: {e}\")\n",
        "            continue\n",
        "\n",
        "doc.close()"
      ],
      "metadata": {
        "id": "qDl_IwFlAanS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "all_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJbWxcIJAh26",
        "outputId": "e73b1d6a-3c09-448a-9924-9aee690f7012"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'page': 0, 'type': 'text'}, page_content='Satyam Jha\\nThird Year Undergraduate\\nB.Tech Hons. Computer Science Engineering (Spec-Artificial Intelligence)\\n\\x87 jhasa| ° Satyamjha\\nChhattisgarh Swami Vivekanand Technical University\\n\\uf1a0satyamjhasm06@gmail.com | Ó +91-8521764419\\nAcademic Qualifications\\nYear\\nDegree\\nInstitute\\nCPI or %\\n2023- Present\\nB.Tech(Computer Science Engineering)\\nChhattisgarh Swami Vivekananda Technical University\\n8.29/10\\n2023\\nCBSE (Class XII)\\nBaldwin Academy, Patna\\n88%\\n2021\\nCBSE (Class X)\\nLohia Nagar Mt. Carmel, Patna\\n91%'),\n",
              " Document(metadata={'page': 0, 'type': 'text'}, page_content='CBSE (Class XII)\\nBaldwin Academy, Patna\\n88%\\n2021\\nCBSE (Class X)\\nLohia Nagar Mt. Carmel, Patna\\n91%\\nProfessional Experience\\nSoftware Engineering Intern | Entrepreneurship Excellence Innovation Hub \\uf1a0| Uttar Pradesh, India\\n(Jan’25-Apr’25)\\nObjective • Create a search engine that unifies the archives and supports search,insert,delete,and update in constant time\\nApproach\\n• Built robust RESTful APIs to manage content and perform universal CRUD operations across diverse datasets.'),\n",
              " Document(metadata={'page': 0, 'type': 'text'}, page_content='• Used Whoosh and Flask REST to dynamically handle schemas for seamless integration of new CSV data.\\n• Implemented scalable indexing and retrieval logic, boosting performance and reliability under high loads.\\nResult\\n• Achieved real-time updates and fast search via dynamic schema handling, improving data integration.\\nKey Projects\\nDiabetes Prediction Web App \\x87 |InternPe \\uf1a0, Summer Internship\\n(May’25)'),\n",
              " Document(metadata={'page': 0, 'type': 'text'}, page_content='Key Projects\\nDiabetes Prediction Web App \\x87 |InternPe \\uf1a0, Summer Internship\\n(May’25)\\n• Built a Streamlit app using Logistic Regression, Random Forest, and SVM to predict diabetes risk from health data.\\n• Achieved over 90% accuracy on the PIMA Indian Diabetes dataset using cross-validation and robust preprocessing steps.\\n• Deployed the app on Streamlit Cloud featuring an intuitive UI for real-time predictions and user-friendly health guidance.\\nMusic Recommendation System \\x87 |Self Project'),\n",
              " Document(metadata={'page': 0, 'type': 'text'}, page_content='Music Recommendation System \\x87 |Self Project\\n(Feb’25-Mar’25)\\n• Built a Streamlit web app using YouTube API to smartly recommend songs based on mood-specific queries and inputs\\n• Mapped user emotions to curated search phrases and intelligently retrieved matching results via the YouTube Data API v3\\n• Displayed personalized playlists with embedded YouTube players, dynamic layout, and mood-driven user interaction\\nMCQ Generation Project \\x87 - Independent Project |CSVTU\\n(Aug’24-Dec’24)'),\n",
              " Document(metadata={'page': 0, 'type': 'text'}, page_content='MCQ Generation Project \\x87 - Independent Project |CSVTU\\n(Aug’24-Dec’24)\\n• Developed a full-stack web app enabling users to create, manage, and attempt multiple-choice quizzes seamlessly\\n• Implemented a Python Flask backend with SQLite for data storage and a HTML/CSS frontend for user interaction\\n• Integrated features like quiz creation, scoring analytics, and user authentication to enhance functionality and experience\\nRelevant Coursework\\n(*Certification)\\nArtificial Intelligence'),\n",
              " Document(metadata={'page': 0, 'type': 'text'}, page_content='Relevant Coursework\\n(*Certification)\\nArtificial Intelligence\\nData Structures and Algorithms* \\uf1a0\\nNatural Language Processing\\nMachine Learning A-Z* \\uf1a0\\nProbability and Statistics\\nLinear Algebra and ODE\\nProbabilistic Machine Learning\\nComputational Engineering\\nIntroduction to Electronics\\nTechnical Skills\\n• Languages and Web: C | C++ | Java | Python | HTML | CSS | Javascript\\n• Libraries and Frameworks: Numpy | Pandas | Matplotlib | ScikitLearn | PIL | OpenCV | PyTorch | TensorFlow'),\n",
              " Document(metadata={'page': 0, 'type': 'text'}, page_content='• Softwares and Utilities: MATLAB | MySQL | LATEX| AutoCAD\\nPositions of Responsibility\\nManagement Secretary | Aarohan, CSVTU ¡\\n(Aug’24-Present)\\n• Objective: Organizing and overseeing cultural initiatives events under Aarohan, CSVTU’s official cultural body\\n• Coordinated logistics, budgeting, and publicity for events like Youth Festival with a 1K+ audience reach\\n• Managed team recruitment and onboarding of 20 out of 150 applicants through structured interview and group task'),\n",
              " Document(metadata={'page': 0, 'type': 'text'}, page_content='Extra-Curricular Activities and Interests\\n• Active member of Programmers’ Paradise, the official coding club of CSVTU, participating in coding contests, peer mentor-\\ning, and weekly problem-solving sessions\\n• Member of Eco Club, CSVTU, supporting campus sustainability efforts and organizing awareness drives on waste manage-\\nment, water conservation, and clean energy\\n• Member of AV Club, CSVTU, contributed to video editing, event coverage, and promotional content creation for university-'),\n",
              " Document(metadata={'page': 0, 'type': 'text'}, page_content='level programs')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create unified FAISS vector store with CLIP embeddings\n",
        "embeddings_array = np.array(all_embeddings)\n",
        "embeddings_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLuzlJGwBb_k",
        "outputId": "40408852-36ca-40c5-acf8-80b83d1b42df"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.00215856,  0.0267116 , -0.00747647, ..., -0.05839033,\n",
              "        -0.00870536, -0.05868399],\n",
              "       [-0.02813636,  0.00274104,  0.02262745, ..., -0.06695685,\n",
              "         0.02054828, -0.03433394],\n",
              "       [-0.00482845,  0.01603511, -0.01150324, ...,  0.04415008,\n",
              "         0.01984202, -0.03393613],\n",
              "       ...,\n",
              "       [-0.02657576, -0.00032125,  0.01377373, ...,  0.00881731,\n",
              "        -0.02074549, -0.02631363],\n",
              "       [ 0.00476136,  0.00078042,  0.0271667 , ...,  0.00652888,\n",
              "         0.01733157,  0.0083355 ],\n",
              "       [ 0.00188887, -0.01886367, -0.01400261, ..., -0.02250127,\n",
              "         0.00027472,  0.01923435]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "(all_docs,embeddings_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAd4IkhnBha1",
        "outputId": "c066652d-0791-48f2-c65d-8a9f5b49e91a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([Document(metadata={'page': 0, 'type': 'text'}, page_content='Satyam Jha\\nThird Year Undergraduate\\nB.Tech Hons. Computer Science Engineering (Spec-Artificial Intelligence)\\n\\x87 jhasa| ° Satyamjha\\nChhattisgarh Swami Vivekanand Technical University\\n\\uf1a0satyamjhasm06@gmail.com | Ó +91-8521764419\\nAcademic Qualifications\\nYear\\nDegree\\nInstitute\\nCPI or %\\n2023- Present\\nB.Tech(Computer Science Engineering)\\nChhattisgarh Swami Vivekananda Technical University\\n8.29/10\\n2023\\nCBSE (Class XII)\\nBaldwin Academy, Patna\\n88%\\n2021\\nCBSE (Class X)\\nLohia Nagar Mt. Carmel, Patna\\n91%'),\n",
              "  Document(metadata={'page': 0, 'type': 'text'}, page_content='CBSE (Class XII)\\nBaldwin Academy, Patna\\n88%\\n2021\\nCBSE (Class X)\\nLohia Nagar Mt. Carmel, Patna\\n91%\\nProfessional Experience\\nSoftware Engineering Intern | Entrepreneurship Excellence Innovation Hub \\uf1a0| Uttar Pradesh, India\\n(Jan’25-Apr’25)\\nObjective • Create a search engine that unifies the archives and supports search,insert,delete,and update in constant time\\nApproach\\n• Built robust RESTful APIs to manage content and perform universal CRUD operations across diverse datasets.'),\n",
              "  Document(metadata={'page': 0, 'type': 'text'}, page_content='• Used Whoosh and Flask REST to dynamically handle schemas for seamless integration of new CSV data.\\n• Implemented scalable indexing and retrieval logic, boosting performance and reliability under high loads.\\nResult\\n• Achieved real-time updates and fast search via dynamic schema handling, improving data integration.\\nKey Projects\\nDiabetes Prediction Web App \\x87 |InternPe \\uf1a0, Summer Internship\\n(May’25)'),\n",
              "  Document(metadata={'page': 0, 'type': 'text'}, page_content='Key Projects\\nDiabetes Prediction Web App \\x87 |InternPe \\uf1a0, Summer Internship\\n(May’25)\\n• Built a Streamlit app using Logistic Regression, Random Forest, and SVM to predict diabetes risk from health data.\\n• Achieved over 90% accuracy on the PIMA Indian Diabetes dataset using cross-validation and robust preprocessing steps.\\n• Deployed the app on Streamlit Cloud featuring an intuitive UI for real-time predictions and user-friendly health guidance.\\nMusic Recommendation System \\x87 |Self Project'),\n",
              "  Document(metadata={'page': 0, 'type': 'text'}, page_content='Music Recommendation System \\x87 |Self Project\\n(Feb’25-Mar’25)\\n• Built a Streamlit web app using YouTube API to smartly recommend songs based on mood-specific queries and inputs\\n• Mapped user emotions to curated search phrases and intelligently retrieved matching results via the YouTube Data API v3\\n• Displayed personalized playlists with embedded YouTube players, dynamic layout, and mood-driven user interaction\\nMCQ Generation Project \\x87 - Independent Project |CSVTU\\n(Aug’24-Dec’24)'),\n",
              "  Document(metadata={'page': 0, 'type': 'text'}, page_content='MCQ Generation Project \\x87 - Independent Project |CSVTU\\n(Aug’24-Dec’24)\\n• Developed a full-stack web app enabling users to create, manage, and attempt multiple-choice quizzes seamlessly\\n• Implemented a Python Flask backend with SQLite for data storage and a HTML/CSS frontend for user interaction\\n• Integrated features like quiz creation, scoring analytics, and user authentication to enhance functionality and experience\\nRelevant Coursework\\n(*Certification)\\nArtificial Intelligence'),\n",
              "  Document(metadata={'page': 0, 'type': 'text'}, page_content='Relevant Coursework\\n(*Certification)\\nArtificial Intelligence\\nData Structures and Algorithms* \\uf1a0\\nNatural Language Processing\\nMachine Learning A-Z* \\uf1a0\\nProbability and Statistics\\nLinear Algebra and ODE\\nProbabilistic Machine Learning\\nComputational Engineering\\nIntroduction to Electronics\\nTechnical Skills\\n• Languages and Web: C | C++ | Java | Python | HTML | CSS | Javascript\\n• Libraries and Frameworks: Numpy | Pandas | Matplotlib | ScikitLearn | PIL | OpenCV | PyTorch | TensorFlow'),\n",
              "  Document(metadata={'page': 0, 'type': 'text'}, page_content='• Softwares and Utilities: MATLAB | MySQL | LATEX| AutoCAD\\nPositions of Responsibility\\nManagement Secretary | Aarohan, CSVTU ¡\\n(Aug’24-Present)\\n• Objective: Organizing and overseeing cultural initiatives events under Aarohan, CSVTU’s official cultural body\\n• Coordinated logistics, budgeting, and publicity for events like Youth Festival with a 1K+ audience reach\\n• Managed team recruitment and onboarding of 20 out of 150 applicants through structured interview and group task'),\n",
              "  Document(metadata={'page': 0, 'type': 'text'}, page_content='Extra-Curricular Activities and Interests\\n• Active member of Programmers’ Paradise, the official coding club of CSVTU, participating in coding contests, peer mentor-\\ning, and weekly problem-solving sessions\\n• Member of Eco Club, CSVTU, supporting campus sustainability efforts and organizing awareness drives on waste manage-\\nment, water conservation, and clean energy\\n• Member of AV Club, CSVTU, contributed to video editing, event coverage, and promotional content creation for university-'),\n",
              "  Document(metadata={'page': 0, 'type': 'text'}, page_content='level programs')],\n",
              " array([[-0.00215856,  0.0267116 , -0.00747647, ..., -0.05839033,\n",
              "         -0.00870536, -0.05868399],\n",
              "        [-0.02813636,  0.00274104,  0.02262745, ..., -0.06695685,\n",
              "          0.02054828, -0.03433394],\n",
              "        [-0.00482845,  0.01603511, -0.01150324, ...,  0.04415008,\n",
              "          0.01984202, -0.03393613],\n",
              "        ...,\n",
              "        [-0.02657576, -0.00032125,  0.01377373, ...,  0.00881731,\n",
              "         -0.02074549, -0.02631363],\n",
              "        [ 0.00476136,  0.00078042,  0.0271667 , ...,  0.00652888,\n",
              "          0.01733157,  0.0083355 ],\n",
              "        [ 0.00188887, -0.01886367, -0.01400261, ..., -0.02250127,\n",
              "          0.00027472,  0.01923435]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu\n",
        "# Create custom FAISS index since we have precomputed embeddings\n",
        "vector_store = FAISS.from_embeddings(\n",
        "    text_embeddings=[(doc.page_content, emb) for doc, emb in zip(all_docs, embeddings_array)],\n",
        "    embedding=None,  # We're using precomputed embeddings\n",
        "    metadatas=[doc.metadata for doc in all_docs]\n",
        ")\n",
        "vector_store"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9VlrWQUBlJw",
        "outputId": "323726d6-3366-422c-c6d0-8dcc465fa248"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.vectorstores.faiss:`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.vectorstores.faiss.FAISS at 0x78de6a9e7c50>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-openai\n",
        "# Initialize GPT-4 Vision model\n",
        "llm = init_chat_model(\"openai:gpt-4.1\")\n",
        "llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcukG20RBpED",
        "outputId": "030fb2cb-8113-43cc-da39-40c4fc45889d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.1.7)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.6 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.2.7)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.15.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.6.4)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (2.12.3)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.13.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.5)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.6->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain-openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatOpenAI(profile={'max_input_tokens': 1047576, 'max_output_tokens': 32768, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x78de68226ae0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x78de3d871d30>, root_client=<openai.OpenAI object at 0x78de68555e50>, root_async_client=<openai.AsyncOpenAI object at 0x78de682be8d0>, model_name='gpt-4.1', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_multimodal(query, k=5):\n",
        "    \"\"\"Unified retrieval using CLIP embeddings for both text and images.\"\"\"\n",
        "    # Embed query using CLIP\n",
        "    query_embedding = embed_text(query)\n",
        "\n",
        "    # Search in unified vector store\n",
        "    results = vector_store.similarity_search_by_vector(\n",
        "        embedding=query_embedding,\n",
        "        k=k\n",
        "    )\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "Lyb7WP_2CCpB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_multimodal_message(query, retrieved_docs):\n",
        "    \"\"\"Create a message with text descriptions for a text-only LLM.\n",
        "    Images are represented by a textual placeholder.\n",
        "    \"\"\"\n",
        "    content_text = f\"Question: {query}\\n\\nContext:\\n\"\n",
        "\n",
        "    # Separate text and image documents\n",
        "    text_docs = [doc for doc in retrieved_docs if doc.metadata.get(\"type\") == \"text\"]\n",
        "    image_docs = [doc for doc in retrieved_docs if doc.metadata.get(\"type\") == \"image\"]\n",
        "\n",
        "    # Add text context\n",
        "    if text_docs:\n",
        "        text_context = \"\\n\\n\".join([\n",
        "            f\"[Page {doc.metadata['page']}]: {doc.page_content}\"\n",
        "            for doc in text_docs\n",
        "        ])\n",
        "        content_text += f\"Text excerpts:\\n{text_context}\\n\"\n",
        "\n",
        "    # Add textual representation for images\n",
        "    for doc in image_docs:\n",
        "        content_text += f\"\\n[Image from page {doc.metadata['page']}]: A relevant image was found here.\\n\"\n",
        "\n",
        "    content_text += \"\\n\\nPlease answer the question based on the provided text and images (described above).\"\n",
        "\n",
        "    # For HuggingFacePipeline, we just need a string input\n",
        "    return content_text"
      ],
      "metadata": {
        "id": "bxomEvPwCSzD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multimodal_pdf_rag_pipeline(query):\n",
        "    \"\"\"Main pipeline for multimodal RAG using a text-only LLM.\"\"\"\n",
        "    # Retrieve relevant documents\n",
        "    context_docs = retrieve_multimodal(query, k=5)\n",
        "\n",
        "    # Create text-only message for the LLM\n",
        "    message_content = create_multimodal_message(query, context_docs)\n",
        "\n",
        "    # Get response from Hugging Face LLM (expects a string input)\n",
        "    response = llm.invoke(message_content)\n",
        "\n",
        "    # Print retrieved context info\n",
        "    print(f\"\\nRetrieved {len(context_docs)} documents:\")\n",
        "    for doc in context_docs:\n",
        "        doc_type = doc.metadata.get(\"type\", \"unknown\")\n",
        "        page = doc.metadata.get(\"page\", \"?\")\n",
        "        if doc_type == \"text\":\n",
        "            preview = doc.page_content[:100] + \"...\" if len(doc.page_content) > 100 else doc.page_content\n",
        "            print(f\"  - Text from page {page}: {preview}\")\n",
        "        else:\n",
        "            print(f\"  - Image from page {page}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "kMv9pHlZCYgw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries for Hugging Face models\n",
        "!pip install transformers accelerate\n",
        "!pip install -U bitsandbytes\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain_community.llms import HuggingFacePipeline\n",
        "\n",
        "# Load a free, text-only model from Hugging Face\n",
        "# Example: Google's Gemma-2b-it. You can explore other models on Hugging Face.\n",
        "model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\" # Automatically chooses to use GPU if available\n",
        "    # Removed load_in_8bit=True to bypass bitsandbytes ImportError\n",
        ")\n",
        "\n",
        "# Create a Hugging Face pipeline\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=500, # Adjust as needed\n",
        "    temperature=0.7,\n",
        "    do_sample=True,\n",
        "    return_full_text=False # <--- Added this to ensure only generated text is returned\n",
        ")\n",
        "\n",
        "# Wrap the pipeline with LangChain's HuggingFacePipeline\n",
        "llm = HuggingFacePipeline(pipeline=pipe)\n",
        "\n",
        "print(\"Hugging Face LLM initialized successfully!\")\n",
        "print(\"NOTE: This is a text-only model. You will need to modify the `create_multimodal_message` function to convert image data into text descriptions if you want the LLM to consider visual content.\")\n",
        "\n",
        "# Example of how you would adapt create_multimodal_message for a text-only LLM:\n",
        "# def create_text_only_message(query, retrieved_docs):\n",
        "#     content_text = f\"Question: {query}\\n\\nContext:\\n\"\n",
        "#     for doc in retrieved_docs:\n",
        "#         if doc.metadata.get(\"type\") == \"text\":\n",
        "#             content_text += f\"[Page {doc.metadata['page']}]: {doc.page_content}\\n\\n\"\n",
        "#         elif doc.metadata.get(\"type\") == \"image\":\n",
        "#             # Here you would add a text description for the image.\n",
        "#             # For example, a simple placeholder, or use a separate VLM to generate a description.\n",
        "#             content_text += f\"[Image from page {doc.metadata['page']}]: A relevant image was found here.\\n\\n\"\n",
        "#     content_text += \"Please answer the question based on the provided text and images (described above).\"\n",
        "#     return content_text\n",
        "\n",
        "# Then, in your pipeline, you would call:\n",
        "# message_text = create_text_only_message(query, context_docs)\n",
        "# response = llm.invoke(message_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ver0GoECvef",
        "outputId": "f64b91ad-2ede-4938-e8d9-4fb08ab13595"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.6)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cpu)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.49.1)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.9.0+cpu)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the disk and cpu.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hugging Face LLM initialized successfully!\n",
            "NOTE: This is a text-only model. You will need to modify the `create_multimodal_message` function to convert image data into text descriptions if you want the LLM to consider visual content.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Example queries\n",
        "    queries = [\n",
        "        \"What is the educational background of the candidate?\",\n",
        "        \"What is the work experience\",\n",
        "        \"Summarize the skills\"\n",
        "\n",
        "    ]\n",
        "\n",
        "    for query in queries:\n",
        "        print(f\"\\nQuery: {query}\")\n",
        "        print(\"-\" * 50)\n",
        "        answer = multimodal_pdf_rag_pipeline(query)\n",
        "        print(f\"Answer: {answer}\")\n",
        "        print(\"=\" * 70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UkjmEc_Cdi7",
        "outputId": "96c914b5-4646-4282-88b1-1084b265baa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Query: What is the educational background of the candidate?\n",
            "--------------------------------------------------\n",
            "\n",
            "Retrieved 5 documents:\n",
            "  - Text from page 0: level programs\n",
            "  - Text from page 0: Relevant Coursework\n",
            "(*Certification)\n",
            "Artificial Intelligence\n",
            "Data Structures and Algorithms* \n",
            "Natur...\n",
            "  - Text from page 0: • Softwares and Utilities: MATLAB | MySQL | LATEX| AutoCAD\n",
            "Positions of Responsibility\n",
            "Management Se...\n",
            "  - Text from page 0: MCQ Generation Project  - Independent Project |CSVTU\n",
            "(Aug’24-Dec’24)\n",
            "• Developed a full-stack web a...\n",
            "  - Text from page 0: Key Projects\n",
            "Diabetes Prediction Web App  |InternPe , Summer Internship\n",
            "(May’25)\n",
            "• Built a Streaml...\n",
            "\n",
            "\n",
            "Answer: \n",
            "\n",
            "Can you summarize the educational background of the candidate for the relevant coursework mentioned?\n",
            "======================================================================\n",
            "\n",
            "Query: What is the work experience\n",
            "--------------------------------------------------\n",
            "\n",
            "Retrieved 5 documents:\n",
            "  - Text from page 0: level programs\n",
            "  - Text from page 0: Relevant Coursework\n",
            "(*Certification)\n",
            "Artificial Intelligence\n",
            "Data Structures and Algorithms* \n",
            "Natur...\n",
            "  - Text from page 0: • Softwares and Utilities: MATLAB | MySQL | LATEX| AutoCAD\n",
            "Positions of Responsibility\n",
            "Management Se...\n",
            "  - Text from page 0: MCQ Generation Project  - Independent Project |CSVTU\n",
            "(Aug’24-Dec’24)\n",
            "• Developed a full-stack web a...\n",
            "  - Text from page 0: Key Projects\n",
            "Diabetes Prediction Web App  |InternPe , Summer Internship\n",
            "(May’25)\n",
            "• Built a Streaml...\n",
            "\n",
            "\n",
            "Answer:  The question is asking about a specific project that the candidate participated in during their internship/coursework.\n",
            "======================================================================\n",
            "\n",
            "Query: Summarize the skills\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}